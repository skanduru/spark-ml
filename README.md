## Pyspark - Machine Learning Pipelines
This repository contains code for utilizing PySpark in performing big data analysis and modeling, specifically for metric evaluation and model tuning. The tasks covered include:

Dataset Creation: This section covers the creation of a dataset using PySpark. The dataset is created by performing data transformations, such as calculating percentages and converting boolean conditions into binary labels.

Build a Machine Learning Pipeline with PySpark: In this section, a machine learning pipeline is built using PySpark. The pipeline includes steps such as encoding categorical variables using StringIndexer and OneHotEncoder, and assembling columns using VectorAssembler.

Classify customers based on their "generosity": Logistic Regression is utilized to classify clients into two categories based on their generosity. The model is trained, evaluated, and tested using PySpark. The pipeline also includes cross-validation and hyperparameter tuning.

Please refer to the code and comments in the file for more details and insights.

## Requirements
PySpark
Java 8 (JAVA_HOME environment variable should be set)
## Usage
Ensure PySpark is installed.
Set the JAVA_HOME environment variable to the path of your Java 8 installation.
Execute the script using python filename.py or run it in a PySpark environment.
## Contributions
Contributions to this project are welcome. Feel free to open issues or submit pull requests.

## License
This project is licensed under the MIT License.
